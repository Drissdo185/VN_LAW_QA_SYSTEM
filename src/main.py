import streamlit as st
import logging
from typing import List
import asyncio
from llama_index.core.base.llms.types import ChatMessage, MessageRole
from llama_index.llms.openai import OpenAI
from llama_index.core import Settings
from llama_index.embeddings.huggingface import HuggingFaceEmbedding

from config.config import ModelConfig, RetrievalConfig, load_and_validate_configs
from config.domain_router import DomainRouter

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class DomainManager:
    def __init__(self):
        self.llm = None
        self.embed_model = None
        self.domain_router = None
        self.initialize_components()
        
    def initialize_components(self):
        """Initialize common components and domain router"""
        try:
            # Initialize embedding model
            self.embed_model = HuggingFaceEmbedding(
                model_name="dangvantuan/vietnamese-document-embedding",
                max_length=256,
                trust_remote_code=True
            )
            
            # Load and validate configs
            model_config, retrieval_config = load_and_validate_configs()
            
            # Initialize LLM
            self.llm = OpenAI(model=model_config.llm_model, temperature=0.1)
            Settings.llm = self.llm
            
            # Initialize domain router
            self.domain_router = DomainRouter(
                llm=self.llm,
                model_config=model_config,
                retrieval_config=retrieval_config
            )
            
            logger.info("Successfully initialized all components")
            
        except Exception as e:
            logger.error(f"Error initializing components: {e}", exc_info=True)
            raise
    
    async def process_question(self, question: str) -> str:
        """Process user question through domain routing and search pipeline"""
        try:
            if not self.domain_router:
                raise ValueError("Domain router not initialized")
                
            # Get results and domain classification
            results, domain = await self.domain_router.route_and_search(question)
            
            if not results or not domain:
                return (
                    "Xin lá»—i, tÃ´i khÃ´ng thá»ƒ tÃ¬m tháº¥y thÃ´ng tin phÃ¹ há»£p Ä‘á»ƒ tráº£ lá»i cÃ¢u há»i cá»§a báº¡n. "
                    "Vui lÃ²ng thá»­ diá»…n Ä‘áº¡t láº¡i cÃ¢u há»i hoáº·c cung cáº¥p thÃªm chi tiáº¿t."
                )
            
            # Generate response from results
            response = await self.generate_response(question, results, domain)
            return response
            
        except Exception as e:
            logger.error(f"Error processing question: {e}", exc_info=True)
            return "ÄÃ£ xáº£y ra lá»—i khi xá»­ lÃ½ cÃ¢u há»i. Vui lÃ²ng thá»­ láº¡i sau."

    async def generate_response(self, question: str, results: List, domain: str) -> str:
        """Generate response based on retrieved documents"""
        context = "\n\n".join([doc.text for doc in results if doc.text])
        
        prompt = f"""Dá»±a trÃªn cÃ¡c tÃ i liá»‡u phÃ¡p lÃ½ vá» {domain} sau Ä‘Ã¢y, vui lÃ²ng tráº£ lá»i cÃ¢u há»i.
Cung cáº¥p cÃ¢u tráº£ lá»i rÃµ rÃ ng, sÃºc tÃ­ch vÃ  trÃ­ch dáº«n cÃ¡c Ä‘iá»u khoáº£n cá»¥ thá»ƒ khi cÃ³ liÃªn quan.

CÃ¢u há»i: {question}

TÃ i liá»‡u phÃ¡p lÃ½:
{context}

Tráº£ lá»i:"""
        
        try:
            response = await self.llm.acomplete(prompt)
            return response.text
        except Exception as e:
            logger.error(f"Error generating response: {e}")
            return "Xin lá»—i, Ä‘Ã£ cÃ³ lá»—i xáº£y ra khi táº¡o cÃ¢u tráº£ lá»i. Vui lÃ²ng thá»­ láº¡i."

def initialize_session_state():
    """Initialize Streamlit session state variables"""
    if "chat_history" not in st.session_state:
        st.session_state.chat_history: List[ChatMessage] = []
    
    if "domain_manager" not in st.session_state:
        st.session_state.domain_manager = DomainManager()

def display_chat_history():
    """Display chat history"""
    for message in st.session_state.chat_history:
        with st.chat_message(message.role.value):
            st.write(message.content)

async def main():
    # Configure Streamlit page
    st.set_page_config(
        page_title="Há»‡ thá»‘ng Tra cá»©u PhÃ¡p lÃ½",
        page_icon="âš–ï¸",
        layout="wide"
    )
    
    # Page header
    st.title("âš–ï¸ Há»‡ thá»‘ng Tra cá»©u VÄƒn báº£n PhÃ¡p lÃ½")
    st.write("Há»— trá»£ tra cá»©u vá»: Giao thÃ´ng ğŸš— | Chá»©ng khoÃ¡n ğŸ“ˆ | Lao Ä‘á»™ng ğŸ‘·")
    
    # Initialize session state
    initialize_session_state()
    
    # Display chat history
    display_chat_history()
    
    # Chat input
    user_input = st.chat_input("Nháº­p cÃ¢u há»i cá»§a báº¡n...")
    
    if user_input:
        # Display user message
        with st.chat_message("user"):
            st.write(user_input)
        
        # Add user message to chat history
        st.session_state.chat_history.append(
            ChatMessage(role=MessageRole.USER, content=user_input)
        )
        
        try:
            # Process question
            with st.spinner("Äang xá»­ lÃ½ cÃ¢u há»i..."):
                response = await st.session_state.domain_manager.process_question(user_input)
            
            # Display assistant response
            with st.chat_message("assistant"):
                st.write(response)
            
            # Add assistant response to chat history
            st.session_state.chat_history.append(
                ChatMessage(role=MessageRole.ASSISTANT, content=response)
            )
            
        except Exception as e:
            st.error("âŒ ÄÃ£ xáº£y ra lá»—i khi xá»­ lÃ½ cÃ¢u há»i cá»§a báº¡n. Vui lÃ²ng thá»­ láº¡i.")
            logger.error(f"Error in main loop: {e}", exc_info=True)

if __name__ == "__main__":
    asyncio.run(main())